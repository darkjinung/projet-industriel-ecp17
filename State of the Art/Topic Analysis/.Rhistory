shiny::runApp('C:/Users/benhamza/AppData/Local/NoBackup/Perso/Data Projects/Mosaic 2017/Mosaic2017/dempApp4')
library(wordcloud2)
nrow(demoFreq)
demoFreq2 <- head(demoFreq,50)
shiny::runApp('C:/Users/benhamza/AppData/Local/NoBackup/Perso/Data Projects/Mosaic 2017/Mosaic2017/dempApp4')
library(RWeka)
setwd("C:\Users\benhamza\AppData\Local\NoBackup\Perso\CentraleSupelec\Projet Industriel\projet-industriel-ecp17\State of the Art\Topic Analysis")
setwd('C:\Users\benhamza\AppData\Local\NoBackup\Perso\CentraleSupelec\Projet Industriel\projet-industriel-ecp17\State of the Art\Topic Analysis')
setwd('C:/Users/benhamza/AppData/Local/NoBackup/Perso/CentraleSupelec/Projet Industriel/projet-industriel-ecp17/State of the Art/Topic Analysis')
ls
ls()
dir()
review.data <- read.csv("./reviews.csv")
review.data <- read.csv("./reviews.csv")
review.data <- read.csv("./reviews.csv")
reviews.data <- read.csv("./reviews.csv")
reviews.data <- read.csv("./reviews.csv")
reviews.data <- read.csv("./reviews.csv")
reviews.data <- read.csv("reviews.csv")
reviews.data <- read.csv("./repdata_data_StormData.csv/repdata_data_StormData.csv")
reviews.data <- read.csv("./sampleSubmission.csv")
str(reviews.data)
reviews.data <- read.csv("./train.tsv/train.tsv")
reviews.data <- read.csv("./train.tsv/train.tsv")
reviews.data <- read.csv2("./train.tsv/train.tsv")
str(reviews.data)
library(dplyr)
View(reviews.data)
reviews.data <- read.csv2("./train.tsv/train.tsv",sep = ",")
reviews.data <- read.csv2("./train.tsv/train.tsv",sep = "    ")
reviews.data <- read.csv2("./train.tsv/train.tsv",sep = "|")
reviews.data <- read.csv2("./train.tsv/train.tsv")
reviews.data <- read.csv2("./consumer-reviews-of-amazon-products/7817_1.csv")
View(reviews.data)
reviews.data <- read.csv2("./consumer-reviews-of-amazon-products/7817_1.csv",sep=",")
help(select)
names(reviews.data)
reviews.init <- select(reviews.data,c(1,20))
View(reviews.init)
dim(reviews.data)
names(reviews.data)
unique(ident())
unique(id)
str(id)
str(reviews.data.id)
str(reviews.data[id])
str(reviews.data[id,])
str(reviews.data[c(id),])
str(reviews.data
)
reviews.data <- read.csv2("./consumer-reviews-of-amazon-products/7817_1.csv",sep=",")
reviews.init <- select(reviews.data,c(1,20))
reviews.init$row_id <- row.names(reviews.init)
reviews.data <- read.csv2("./consumer-reviews-of-amazon-products/7817_1.csv",sep=",")
reviews.init <- select(reviews.data,c(1,20))
reviews.init$row_id <- row.names(reviews.init)
reviews.init <- select(reviews.init,c(3,1,2))
reviews.data <- read.csv2("./consumer-reviews-of-amazon-products/7817_1.csv",sep=",")
reviews.init <- merge(row.names(reviews.data),
select(reviews.data,c(1,20)
)
)
setwd('C:/Users/benhamza/AppData/Local/NoBackup/Perso/CentraleSupelec/Projet Industriel/projet-industriel-ecp17/State of the Art/Topic Analysis')
reviews.data <- read.csv2("./consumer-reviews-of-amazon-products/7817_1.csv",sep=",")
reviews.init <- select(reviews.data,c(1,20))
reviews.init$row_id <- row.names(reviews.init)
dim(reviews.init)
names(reviews.init)
str(reviews.init)
library(tm)
colnames(reviews.init)
reviews.init$reviews.text[12]
reviews.init$reviews.text[12] %>% as.String()
#convert text to matrix
reviews_corpus <- Corpus(VectorSource(as.vector(reviews.init$reviews.text)))
#remmove stop words
stoplist <- read.csv("stop-word-list.csv", header=TRUE, stringsAsFactors = FALSE)
stoplist
View(stoplist)
#remmove stop words
stoplist <- read.csv("stop-word-list.csv", header=FALSE, stringsAsFactors = FALSE)
reviews_corpus <- Corpus(VectorSource(as.vector(reviews.init$reviews.text)))
#remove punctation
reviews_corpus <- tm_map(reviews_corpus, content_transformer(removePunctuation))
#lowering texts
reviews_corpus <- tm_map(reviews_corpus, content_transformer(tolower))
#remove whitespace
reviews_corpus <- tm_map(reviews_corpus , content_transformer(stripWhitespace))
#remmove stop words
stoplist <- read.csv("stop-word-list.csv", header=FALSE, stringsAsFactors = FALSE)
stoplist<-stoplist$V1
reviews_corpus  <- tm_map(reviews_corpus , content_transformer(removeWords), stoplist)
#stemming
reviews_corpus  <- tm_map(reviews_corpus , content_transformer(stemDocument), language = "english")
### Corpus to Matrix ###
reviews_DTM <- DocumentTermMatrix(reviews_corpus)
dim(reviews_DTM)
dim(reviews.init)
reviews_DTM[1:3,1:10]
inspect(reviews_DTM[1:3,1:10])
inspect(reviews_DTM[1:3,1:10])
reviews.data <- read.csv2("./consumer-reviews-of-amazon-products/7817_1.csv",sep=",")
reviews.init <- select(reviews.data,c(1,20))
reviews.init$row_id <- row.names(reviews.init)
### Text Pre-Proessing ###
#compose the corpus
reviews_corpus <- Corpus(VectorSource(as.vector(reviews.init$reviews.text)))
#remove punctation
reviews_corpus <- tm_map(reviews_corpus, content_transformer(removePunctuation))
#remove numbers
reviews_corpus <- tm_map(reviews_corpus, content_transformer(removeNumbers))
#lowering texts
reviews_corpus <- tm_map(reviews_corpus, content_transformer(tolower))
#remove whitespace
reviews_corpus <- tm_map(reviews_corpus , content_transformer(stripWhitespace))
#remmove stop words
stoplist <- read.csv("stop-word-list.csv", header=FALSE, stringsAsFactors = FALSE)
stoplist<-stoplist$V1
reviews_corpus  <- tm_map(reviews_corpus , content_transformer(removeWords), stoplist)
#stemming
reviews_corpus  <- tm_map(reviews_corpus , content_transformer(stemDocument), language = "english")
### Corpus to Matrix ###
reviews_DTM <- DocumentTermMatrix(reviews_corpus)
reviews_DTM <- DocumentTermMatrix(reviews_corpus)
#remove sparse terms
reviews_DTM <- removeSparseTerms(reviews_DTM , 0.990)
#find freq terms
findFreqTerms(reviews_DTM, 20)
findFreqTerms(reviews_DTM, 100)
#find freq terms
findFreqTerms(reviews_DTM, 200)
#find freq terms
findFreqTerms(reviews_DTM, 300)
#find freq terms
findFreqTerms(reviews_DTM, 400)
#find freq terms
findFreqTerms(reviews_DTM, 600)
#find freq terms
findFreqTerms(reviews_DTM, 700)
#find freq terms
findFreqTerms(reviews_DTM, 900)
#find freq terms
findFreqTerms(reviews_DTM, 1000)
reviews.data <- read.csv2("./consumer-reviews-of-amazon-products/7817_1.csv",sep=",")
reviews.init <- select(reviews.data,c(1,20))
reviews.init$row_id <- row.names(reviews.init)
### Text Pre-Proessing ###
#compose the corpus
reviews_corpus <- Corpus(VectorSource(as.vector(reviews.init$reviews.text)))
#remove punctation
reviews_corpus <- tm_map(reviews_corpus, content_transformer(removePunctuation))
#remove numbers
reviews_corpus <- tm_map(reviews_corpus, content_transformer(removeNumbers))
#lowering texts
reviews_corpus <- tm_map(reviews_corpus, content_transformer(tolower))
#remove whitespace
reviews_corpus <- tm_map(reviews_corpus , content_transformer(stripWhitespace))
#remmove stop words
stoplist <- read.csv("stop-word-list.csv", header=FALSE, stringsAsFactors = FALSE)
stoplist<-stoplist$V1
reviews_corpus  <- tm_map(reviews_corpus , content_transformer(removeWords), stoplist)
#stemming
#reviews_corpus  <- tm_map(reviews_corpus , content_transformer(stemDocument), language = "english")
### Corpus to Matrix ###
reviews_DTM <- DocumentTermMatrix(reviews_corpus)
#remove sparse terms
reviews_DTM <- removeSparseTerms(reviews_DTM , 0.990)
#find freq terms
findFreqTerms(reviews_DTM, 1000)
dim(reviews.init)
dim(reviews_DTM)
setwd('C:/Users/benhamza/AppData/Local/NoBackup/Perso/CentraleSupelec/Projet Industriel/projet-industriel-ecp17/State of the Art/Topic Analysis')
reviews.data <- read.csv2("./consumer-reviews-of-amazon-products/7817_1.csv",sep=",")
reviews.init <- select(reviews.data,c(1,20))
reviews.init$row_id <- row.names(reviews.init)
### Text Pre-Proessing ###
#compose the corpus
reviews_corpus <- Corpus(VectorSource(as.vector(reviews.init$reviews.text)))
#remove punctation
reviews_corpus <- tm_map(reviews_corpus, content_transformer(removePunctuation))
#remove numbers
reviews_corpus <- tm_map(reviews_corpus, content_transformer(removeNumbers))
#lowering texts
reviews_corpus <- tm_map(reviews_corpus, content_transformer(tolower))
#remove whitespace
reviews_corpus <- tm_map(reviews_corpus , content_transformer(stripWhitespace))
#remmove stop words
stoplist <- read.csv("stop-word-list.csv", header=FALSE, stringsAsFactors = FALSE)
stoplist<-stoplist$V1
reviews_corpus  <- tm_map(reviews_corpus , content_transformer(removeWords), stoplist)
#stemming
#reviews_corpus  <- tm_map(reviews_corpus , content_transformer(stemDocument), language = "english")
### Corpus to Matrix ###
reviews_DTM <- DocumentTermMatrix(reviews_corpus)
#remove sparse terms
reviews_DTM <- removeSparseTerms(reviews_DTM , 0.990)
#find freq terms
#findFreqTerms(reviews_DTM, 1000)
#set burn in
burnin <-1000
#set iterations
iter<-500
#thin the spaces between samples
thin <- 500
#set random starts at 5
nstart <-5
#use random integers as seed
seed <- list(254672,109,122887,145629037,2)
# return the highest probability as the result
best <-TRUE
#set number of topics
k <-5
#run the LDA model
ldaOut <- LDA(dtm,k, method="Gibbs", control=
list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
library(topicmodels)
ldaOut <- LDA(dtm,k, method="Gibbs", control=
list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
ldaOut <- LDA(reviews_DTM,k, method="Gibbs", control=
list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
### Corpus to Matrix ###
reviews_DTM <- DocumentTermMatrix(reviews_corpus)
#remove sparse terms
reviews_DTM <- removeSparseTerms(reviews_DTM , 0.990)
ldaOut <- LDA(reviews_DTM,k, method="Gibbs", control=
list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
reviews_DTM <- DocumentTermMatrix(reviews_corpus)
#remove sparse terms
reviews_DTM <- removeSparseTerms(reviews_DTM , 0.9)
ldaOut <- LDA(reviews_DTM,k, method="Gibbs", control=
list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
#remove lines with zero lines
reviews_DTM <- reviews_DTM[rowSums(reviews_DTM[,-1]) != 0,]
rowSums(reviews_DTM[,-1])
reviews_DTM[,-1]
reviews_DTM[,]
rowSums(reviews_DTM[,])
rowSums(reviews_DTM)
help("rowSums")
rowSums(reviews_DTM[,-1],dim=2)
rowSums(reviews_DTM)
class(reviews_DTM)
rowSums(as.matrix(reviews_DTM))
#remove lines with zero lines
reviews_DTM <- reviews_DTM[rowSums(as.matrix(reviews_DTM[,-1])) != 0,]
ldaOut <- LDA(reviews_DTM,k, method="Gibbs", control=
list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
terms(ldaOut,6)
### Run Latent Dirichlet Allocation (LDA) using Gibbs Sampling
#set burn in
burnin <-1000
#set iterations
iter<-500
#thin the spaces between samples
thin <- 500
#set random starts at 5
nstart <-3
#use random integers as seed
seed <- list(254672,109,122887,145629037,2)
# return the highest probability as the result
best <-TRUE
#set number of topics
k <-5
#run the LDA model
ldaOut <- LDA(reviews_DTM,k, method="Gibbs", control=
list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
terms(ldaOut,6)
### Run Latent Dirichlet Allocation (LDA) using Gibbs Sampling
#set burn in
burnin <-1000
#set iterations
iter<-500
#thin the spaces between samples
thin <- 500
#set random starts at 5
nstart <-5
#use random integers as seed
seed <- list(254672,109,122887,145629037,2)
# return the highest probability as the result
best <-TRUE
#set number of topics
k <-3
#run the LDA model
ldaOut <- LDA(reviews_DTM,k, method="Gibbs", control=
list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
terms(ldaOut,6)
topics(ldaOut)
help(LDA)
### Run Latent Dirichlet Allocation (LDA) using Gibbs Sampling
#set burn in
burnin <-1000
#set iterations
iter<-500
#thin the spaces between samples
thin <- 500
#set random starts at 5
nstart <-5
#use random integers as seed
seed <- list(254672,109,122887,145629037,2)
# return the highest probability as the result
best <-TRUE
#set number of topics
k <-0
#run the LDA model
ldaOut <- LDA(reviews_DTM,k, method="Gibbs", control=
list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
#find freq terms
#findFreqTerms(reviews_DTM, 1000)
### Run Latent Dirichlet Allocation (LDA) using Gibbs Sampling
#set burn in
burnin <-1000
#set iterations
iter<-500
#thin the spaces between samples
thin <- 500
#set random starts at 5
nstart <-5
#use random integers as seed
seed <- list(254672,109,122887,145629037,2)
# return the highest probability as the result
best <-TRUE
#set number of topics
k <-0
#run the LDA model
ldaOut <- LDA(reviews_DTM,method="Gibbs", control=
list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
### Run Latent Dirichlet Allocation (LDA) using Gibbs Sampling
#set burn in
burnin <-1000
#set iterations
iter<-100
#thin the spaces between samples
thin <- 500
#set random starts at 5
nstart <-5
#use random integers as seed
seed <- list(254672,109,122887,145629037,2)
# return the highest probability as the result
best <-TRUE
#set number of topics
k <-7
#run the LDA model
ldaOut <- LDA(reviews_DTM,k, method="Gibbs", control=
list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
### Run Latent Dirichlet Allocation (LDA) using Gibbs Sampling
#set burn in
burnin <-1000
#set iterations
iter<-500
#thin the spaces between samples
thin <- 500
#set random starts at 5
nstart <-5
#use random integers as seed
seed <- list(254672,109,122887,145629037,2)
# return the highest probability as the result
best <-TRUE
#set number of topics
k <-7
#run the LDA model
ldaOut <- LDA(reviews_DTM,k, method="Gibbs", control=
list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
terms(ldaOut,6)
terms(ldaOut,6)
