shiny::runApp('C:/Users/benhamza/AppData/Local/NoBackup/Perso/Data Projects/Mosaic 2017/Mosaic2017/dempApp4')
library(wordcloud2)
nrow(demoFreq)
demoFreq2 <- head(demoFreq,50)
shiny::runApp('C:/Users/benhamza/AppData/Local/NoBackup/Perso/Data Projects/Mosaic 2017/Mosaic2017/dempApp4')
library(RWeka)
s <- paste(c("Pierre Vinken, 61 years old, will join the board as a ",
"nonexecutive director Nov. 29.\n",
"Mr. Vinken is chairman of Elsevier N.V., ",
"the Dutch publishing group."),
collapse = "")
s
s <- paste(c("Pierre Vinken, 61 years old, will join the board as a ",
"nonexecutive director Nov. 29. ",
"Mr. Vinken is chairman of Elsevier N.V., ",
"the Dutch publishing group."),
collapse = "")
## Requires package openNLPmodels.en from the repository at
## <http://datacube.wu.ac.at>.
require("NLP")
s
s <- as.String(s)
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
pos_tag_annotator    <- Maxent_POS_Tag_Annotator()
install.packages("openNLPdata")
install.packages("rJava")
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
pos_tag_annotator    <- Maxent_POS_Tag_Annotator()
install.packages("openNLP")
require("openNLP")
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
pos_tag_annotator    <- Maxent_POS_Tag_Annotator()
a3 <- annotate(s,list(sent_token_annotator,
word_token_annotator,
pos_tag_annotator)
)
a3
annotate(s, Maxent_Chunk_Annotator(), a3)
install.packages("openNLPmodels.en")
require("openNLPmodels.en")
require("openNLPmodels.en")
install.packages("cleanNLP")
download_clean_nlp()
library(cleanNLP)
download_clean_nlp()
library(cleanNLP)
download_clean_nlp()
cleanNLP::download_core_nlp()
install.packages("RCurl")
cleanNLP::download_core_nlp()
dir(output_loc)
dir(output_loc)
cleanNLP::download_core_nlp()
set_language("en", 1)
cleanNLP::set_language("en", 1)
set_language("en", 1)
library(cleanNLP)
set_language("en", 1)
cleanNLP::init_clean_nlp()
init_clean_nlp()
set_language("en")
library(cleanNLP)
set_language("en")
## Requires package openNLPmodels.en from the repository at
## <http://datacube.wu.ac.at>.
require("NLP")
require("openNLP")
require("openNLPdata")
require("rJava")
require("openNLPmodels.en")
## Some text.
s <- paste(c("Pierre Vinken, 61 years old, will join the board as a ",
"nonexecutive director Nov. 29. ",
"Mr. Vinken is chairman of Elsevier N.V., ",
"the Dutch publishing group."),
collapse = "")
s <- as.String(s)
## Chunking needs word token annotations with POS tags.
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
pos_tag_annotator    <- Maxent_POS_Tag_Annotator()
a3 <- annotate(s,list(sent_token_annotator,
word_token_annotator,
pos_tag_annotator)
)
annotate(s, Maxent_Chunk_Annotator(), a3)
annotate(s, Maxent_Chunk_Annotator(probs = TRUE), a3)
require("NLP")
require("openNLP")
require("openNLPdata")
require("rJava")
require("openNLPmodels.en")
install.packages("openNLPmodels.en", repos = "http://datacube.wu.ac.at")
require("NLP")
require("openNLP")
require("openNLPdata")
require("rJava")
require("openNLPmodels.en")
s <- paste(c("Pierre Vinken, 61 years old, will join the board as a ",
"nonexecutive director Nov. 29. ",
"Mr. Vinken is chairman of Elsevier N.V., ",
"the Dutch publishing group."),
collapse = "")
s <- as.String(s)
s
sent_token_annotator <- Maxent_Sent_Token_Annotator()
sent_token_annotator()
sent_token_annotator(s)
s
len(s)
size(s)
length(s)
nchar(s)
s[1:84]
s[1,84]
s[86,153]
man(openNLP)
help(openNLP)
??openNLP
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
pos_tag_annotator    <- Maxent_POS_Tag_Annotator()
chunck_annotator     <- Maxent_Chunk_Annotator()
entity_annotator     <- Maxent_Entity_Annotator()
parse_annotator      <- Parse_Annotator()
s
sent_token_annotator(s)
ss <- sent_token_annotator(s)
ss
type'ss'
type(ss)
class(ss)
names(ss)
help(Annotation)
sw <- Parse_Annotator(s)
word_token_annotator(s)
word_token_annotator <- Maxent_Word_Token_Annotator()
word_token_annotator(s)
word_token_annotator(ss)
wordpunct_tokenizer(s)
words(s)
words(s)
words(ss)
pos_tag_annotator(s)
chunck_annotator(s)
word_token_annotator()
word_token_annotator
word_token_annotator(s)
word_token_annotator(s,ss)
ws <- word_token_annotator(s,ss)
pos_tag_annotator(s,ss,ws)
pos_tag_annotator(ss,ws)
chunck_annotator     <- Maxent_Chunk_Annotator()
ss <- sent_token_annotator(s)
ws <- word_token_annotator(s,ss)
ps <- pos_tag_annotator(ss,ws)
ss
ws
ps
s[16,17]
s[19,23]
chunck_annotator(s)
chunck_annotator(s,ss)
chunck_annotator(s,sw)
chunck_annotator(s,ws)
chunck_annotator(ws)
entity_annotator(s)
entity_annotator(ws)
entity_annotator(s,ws)
a3 <- annotate(s,list(sent_token_annotator,
word_token_annotator,
pos_tag_annotator)
)
annotate(s, Maxent_Chunk_Annotator(), a3)
annotate(s, Maxent_Chunk_Annotator(probs = TRUE), a3)
annotate(s, Maxent_Entity_Annotator(), a3)
s[1,13]
entity_annotator(s)
entity_annotator(ss)
entity_annotator(ws)
entity_annotator(s,ws)
entity_annotator(s,ss)
entity_annotator(s,ws)
annotate(s, Maxent_Entity_Annotator()(probs = TRUE), a3)
annotate(s, Maxent_Entity_Annotator(probs = TRUE), a3)
annotate(s, Maxent_Entity_Annotator(probs = TRUE), a3)
annotate(s, Parse_Annotator()	, a3)
memory.limit()
memory.limit()
memory.size()
memory.limit(size=15000)
memory.limit(size=max)
memory.size(max = 15000)
annotate
annotate(s, Parse_Annotator()	, a3)
###############################################################
a2 <- annotate(s, list(sent_token_annotator, word_token_annotator))
## Entity recognition for persons.
entity_annotator <- Maxent_Entity_Annotator()
entity_annotator
annotate(s, entity_annotator, a2)
## Directly:
entity_annotator(s, a2)
## And slice ...
s[entity_annotator(s, a2)]
## Variant with sentence probabilities as features.
annotate(s, Maxent_Entity_Annotator(probs = TRUE), a2)
annotate(s, Maxent_Chunk_Annotator(), a3)
## Requires package openNLPmodels.en from the repository at
## <http://datacube.wu.ac.at>.
require("NLP")
require("openNLP")
require("openNLPdata")
require("rJava")
require("openNLPmodels.en")
## Some text.
s <- paste(c("Pierre Vinken, 61 years old, will join the board as a ",
"nonexecutive director Nov. 29. ",
"Mr. Vinken is chairman of Elsevier N.V., ",
"the Dutch publishing group."),
collapse = "")
s <- as.String(s)
## Chunking needs word token annotations with POS tags.
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
pos_tag_annotator    <- Maxent_POS_Tag_Annotator()
#ss <- sent_token_annotator(s)
#ws <- word_token_annotator(s,ss)
#ps <- pos_tag_annotator(ss,ws)
a3 <- annotate(s,list(sent_token_annotator,
word_token_annotator,
pos_tag_annotator)
annotate(s, Maxent_Chunk_Annotator(), a3)
annotate(s, Maxent_Chunk_Annotator(), a3)
annotate(s, Maxent_Entity_Annotator(), a3)
s[entity_annotator(s, a3)]
entity_annotator <- Maxent_Entity_Annotator()
s[entity_annotator(s, a3)]
annotate(s, Maxent_Chunk_Annotator(), a3)
annotate(s, Maxent_Entity_Annotator(), a3)
annotate(s, Parse_Annotator()	, a3)
require("NLP")
require("openNLP")
require("openNLPdata")
require("rJava")
require("openNLPmodels.en")
## Some text.
s <- paste(c("Pierre Vinken, 61 years old, will join the board as a ",
"nonexecutive director Nov. 29. ",
"Mr. Vinken is chairman of Elsevier N.V., ",
"the Dutch publishing group."),
collapse = "")
s <- as.String(s)
## Chunking needs word token annotations with POS tags.
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
pos_tag_annotator    <- Maxent_POS_Tag_Annotator()
a3 <- annotate(s,list(sent_token_annotator,
word_token_annotator,
pos_tag_annotator)
)
annotate(s, Parse_Annotator()	, a3)
annotate(s, Maxent_Chunk_Annotator(), a3)
s[25,27]
annotate(s, Parse_Annotator()	, a3)
require("NLP")
require("openNLP")
require("openNLPdata")
require("rJava")
require("openNLPmodels.en")
## Some text.
s <- paste(c("Pierre Vinken, 61 years old, will join the board as a ",
"nonexecutive director Nov. 29. ",
"Mr. Vinken is chairman of Elsevier N.V., ",
"the Dutch publishing group."),
collapse = "")
s <- as.String(s)
## Chunking needs word token annotations with POS tags.
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
pos_tag_annotator    <- Maxent_POS_Tag_Annotator()
a3 <- annotate(s,list(sent_token_annotator,
word_token_annotator,
pos_tag_annotator)
)
annotate(s, Parse_Annotator()	, a3)
??openNLP
install.packages("coreNLP")
require(coreNLP)
initCoreNLP()
downloadCoreNLP()
initCoreNLP()
initCoreNLP(mem="10g")
gc(); memory.limit(1e+10)
gc();
memory.limit()
memory.limit()
initCoreNLP(mem="10g")
require(coreNLP)
initCoreNLP(mem="10g")
options(java.parameters = "-Xmx8000m")
require(coreNLP)
options(java.parameters = "-Xmx12000m")
require(coreNLP)
initCoreNLP()
initCoreNLP()
initCoreNLP
initCoreNLP(mem="15000")
require(coreNLP)
initCoreNLP(mem="15000")
initCoreNLP <-function (libLoc, type = c("english", "english_all", "english_fast",
"arabic", "chinese", "french", "german", "spanish")
, parameterFile = NULL
, mem = "4g")
{
if (missing(libLoc)) {
libLoc = paste0(system.file("extdata", package = "coreNLP"),
"/stanford-corenlp-full-2015-12-09")
if (!file.exists(libLoc))
stop("Please run downloadCoreNLP() in order to install required jar files.")
}
if (!file.exists(libLoc) || !file.info(libLoc)$isdir)
stop("libLoc does not point to an existing directory path")
path = Sys.glob(paste0(libLoc, "/*.jar"))
options(java.parameters = paste0("-Xmx", mem))
rJava::.jinit()
rJava::.jaddClassPath(path)
len = length(grep("stanford-corenlp-", basename(rJava::.jclassPath())))
if (len == 0L)
stop("The coreNLP jar files are were not found in libLoc.")
if (len < 4L)
warning("The set of coreNLP jar files may be incomplete. Proceed with caution")
if (is.null(parameterFile)) {
type = match.arg(type)
basepath = system.file("extdata", package = "coreNLP")
if (type == "english")
path = sprintf("%s/%s", basepath, "/StanfordCoreNLP.properties")
if (type == "english_all")
path = sprintf("%s/%s", basepath, "/StanfordCoreNLP-english-all.properties")
if (type == "english_fast")
path = sprintf("%s/%s", basepath, "/StanfordCoreNLP-english-fast.properties")
if (type == "arabic")
path = sprintf("%s/%s", basepath, "/StanfordCoreNLP-arabic.properties")
if (type == "chinese")
path = sprintf("%s/%s", basepath, "/StanfordCoreNLP-chinese.properties")
if (type == "french")
path = sprintf("%s/%s", basepath, "/StanfordCoreNLP-french.properties")
if (type == "german")
path = sprintf("%s/%s", basepath, "/StanfordCoreNLP-german.properties")
if (type == "spanish")
path = sprintf("%s/%s", basepath, "/StanfordCoreNLP-spanish.properties")
}
else {
path = Sys.glob(paste0(parameterFile[[1]]))
}
rJava::.jaddClassPath(dirname(path))
if (!is.null(volatiles$cNLP))
rJava::.jcall(volatiles$cNLP, "V", "clearAnnotatorPool")
volatiles$cNLP = rJava::.jnew("edu.stanford.nlp.pipeline.StanfordCoreNLP",
basename(path))
volatiles$xmlOut = rJava::.jnew("edu.stanford.nlp.pipeline.XMLOutputter")
}
initCoreNLP()
require(coreNLP)
initCoreNLP()
require(coreNLP)
setwd("C:/Users/benhamza/AppData/Local/NoBackup/Perso/CentraleSupelec/Projet Industriel/projet-industriel-ecp17/State of the Art/Deep learning & Machine learning")
summary(iris)
summary(iris)
names(iris)
requir(dplyr)
require(dplyr)
View(iris)
str(ir.model)
